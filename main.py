#!/usr/bin/env python3
"""
Mac M2 ç»ˆæè¯­éŸ³å…‹éš†å·¥å…· - æ”¯æŒå¾®ä¿¡å®æ—¶è¯­éŸ³
ç‰ˆæœ¬ï¼š2.2 (æ€§èƒ½ä¼˜åŒ–ç‰ˆ)
"""

import os
import sys
import time
import argparse
import numpy as np
import sounddevice as sd
from pathlib import Path
import coremltools as ct
import torch
import torch.mps
from concurrent.futures import ThreadPoolExecutor
from queue import Queue, Empty

# é…ç½®åŒº
MODEL_NAME = "zh-CN/baker/tacotron2-DDC-GST"   # è‹¹æœä¼˜åŒ–æ¨¡å‹
CORE_ML_MODEL = "tts_model.mlpackage"          # è½¬æ¢åçš„ Core ML æ¨¡å‹
SAMPLE_RATE = 24000                            # è‹¹æœéŸ³é¢‘ç¡¬ä»¶é‡‡æ ·ç‡
MAX_TEXT_LENGTH = 100                          # æœ€å¤§è¾“å…¥å­—ç¬¦æ•°
DEVICE = "mps" if torch.backends.mps.is_available() else "cpu"

# ç”¨äºé˜Ÿåˆ—ç¼“å†²
QUEUE_TIMEOUT = 0.1  # é˜Ÿåˆ—å–æ•°æ®è¶…æ—¶æ—¶é—´

class M2TTSEngine:
    def __init__(self, voice_sample: str):
        self.voice_sample = voice_sample
        self._setup_hardware()
        self._load_model()
        self._setup_audio()
        self._warmup()

    def _setup_hardware(self):
        """è®¾ç½® M2 èŠ¯ç‰‡å‚æ•°"""
        torch.mps.set_per_process_memory_fraction(0.7)
        os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"

    def _load_model(self):
        """åŠ è½½ Core ML æ¨¡å‹ï¼Œè‹¥ä¸å­˜åœ¨åˆ™ä½¿ç”¨ PyTorch ä½œä¸ºåå¤‡"""
        try:
            if Path(CORE_ML_MODEL).exists():
                self.model = ct.models.MLModel(
                    CORE_ML_MODEL,
                    compute_units=ct.ComputeUnit.ALL
                )
                print("âœ… Core ML æ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                print("âš ï¸ æœªæ‰¾åˆ° Core ML æ¨¡å‹ï¼Œä½¿ç”¨ Metal åŠ é€Ÿçš„ PyTorch")
                from TTS.api import TTS
                self.tts = TTS(
                    model_name=MODEL_NAME,
                    vocoder_name="zh-CN/baker/hifigan_simple",
                    progress_bar=False
                ).to(DEVICE)
        except Exception as e:
            sys.exit(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

    def _setup_audio(self):
        """æ£€æŸ¥éŸ³é¢‘è®¾å¤‡è®¾ç½®"""
        try:
            sd.check_output_settings(device="BlackHole 2ch")
        except sd.PortAudioError:
            sys.exit("âŒ è¯·å®‰è£… BlackHole å¹¶é…ç½®èšåˆè®¾å¤‡")

    def _warmup(self):
        """é¢„çƒ­æ¨¡å‹ï¼Œå‡å°‘é¦–æ¬¡ç”Ÿæˆå»¶æ—¶"""
        start = time.monotonic()
        self.generate("é¢„çƒ­æ¨¡å‹")
        print(f"ğŸ”¥ é¢„çƒ­å®Œæˆ (è€—æ—¶ {time.monotonic()-start:.1f}s)")

    def _coreml_inference(self, text: str) -> np.ndarray:
        """ä½¿ç”¨ Core ML æ¨ç†"""
        inputs = {"text": self._preprocess_text(text)}
        mel = self.model.predict(inputs)["mel"]
        return self._vocoder(mel)

    def _pytorch_inference(self, text: str) -> np.ndarray:
        """ä½¿ç”¨ PyTorch æ¨ç†"""
        with torch.autocast(DEVICE), torch.no_grad():
            return self.tts.tts(
                text=text,
                speaker_wav=self.voice_sample,
                speed=1.2
            )

    def _preprocess_text(self, text: str) -> np.ndarray:
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼åºåˆ—"""
        return np.array([ord(c) for c in text], dtype=np.float32)

    def _vocoder(self, mel: np.ndarray) -> np.ndarray:
        """è°ƒç”¨å£°ç å™¨ç”ŸæˆéŸ³é¢‘"""
        tensor = torch.from_numpy(mel).to(DEVICE)
        with torch.inference_mode():
            return self.tts.vocoder.decode(tensor).cpu().numpy()

    def generate(self, text: str) -> np.ndarray:
        """ç”Ÿæˆè¯­éŸ³ï¼Œè‡ªåŠ¨é€‰æ‹©æ¨ç†åç«¯"""
        if len(text) > MAX_TEXT_LENGTH:
            print(f"âš ï¸ æ–‡æœ¬è¿‡é•¿ (æœ€å¤§ {MAX_TEXT_LENGTH} å­—ç¬¦)")
            return None

        try:
            start_time = time.monotonic()
            if hasattr(self, "model"):
                audio = self._coreml_inference(text)
            else:
                audio = self._pytorch_inference(text)
            print(f"ğŸ•’ ç”Ÿæˆè€—æ—¶: {(time.monotonic()-start_time)*1000:.0f}ms")
            return audio.astype(np.float32)
        except torch.mps.OutOfMemoryError:
            print("âš ï¸ GPU å†…å­˜ä¸è¶³ï¼Œé‡Šæ”¾ç¼“å­˜åé‡è¯•")
            torch.mps.empty_cache()
            return self.generate(text)

    def stream_to_wechat(self, audio: np.ndarray):
        """æ’­æ”¾ç”Ÿæˆçš„éŸ³é¢‘åˆ°å¾®ä¿¡è®¾å¤‡"""
        try:
            sd.play(audio, SAMPLE_RATE, device="BlackHole 2ch")
            sd.wait()
        except sd.PortAudioError as e:
            print(f"âš ï¸ éŸ³é¢‘æ’­æ”¾å¤±è´¥: {e}")

class CLIInterface:
    def __init__(self, engine: M2TTSEngine):
        self.engine = engine
        self.task_queue = Queue()
        self.executor = ThreadPoolExecutor(max_workers=2)

    def run(self):
        """å¯åŠ¨è¾“å…¥ç›‘å¬ä¸ä»»åŠ¡å¤„ç†çº¿ç¨‹"""
        print("\nğŸ¤ è¾“å…¥æ–‡æœ¬ (Enter å‘é€ | Ctrl+C é€€å‡º):")
        # å¯åŠ¨ä»»åŠ¡å¤„ç†çº¿ç¨‹
        self.executor.submit(self._process_tasks)

        try:
            while True:
                text = input("> ").strip()
                if text:
                    self.task_queue.put(text)
        except KeyboardInterrupt:
            print("\nğŸ›‘ æ­£åœ¨é€€å‡º...")
            self.executor.shutdown(wait=True)
            sys.exit()

    def _process_tasks(self):
        """ä»é˜Ÿåˆ—ä¸­å–æ–‡æœ¬ç”Ÿæˆè¯­éŸ³å¹¶æ’­æ”¾"""
        while True:
            try:
                text = self.task_queue.get(timeout=QUEUE_TIMEOUT)
                audio = self.engine.generate(text)
                if audio is not None:
                    # æ’­æ”¾éŸ³é¢‘ä¹Ÿæ”¾åˆ°çº¿ç¨‹æ± æ‰§è¡Œï¼Œé¿å…é˜»å¡ç”Ÿæˆæµç¨‹
                    self.executor.submit(self.engine.stream_to_wechat, audio)
            except Empty:
                continue

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="M2 è¯­éŸ³å…‹éš†å·¥å…·")
    parser.add_argument("--voice", required=True, help="è¯­éŸ³æ ·æœ¬æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    if not Path(args.voice).exists():
        sys.exit(f"âŒ è¯­éŸ³æ–‡ä»¶ {args.voice} ä¸å­˜åœ¨")

    engine = M2TTSEngine(args.voice)
    cli = CLIInterface(engine)
    cli.run()
